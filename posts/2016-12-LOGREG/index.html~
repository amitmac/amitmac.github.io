<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <title>Logistic Regression - About Learning</title>
		<meta charset="utf-8">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <!--mobile first-->
        <meta name="viewport" content="width=device-width, initial-scale=1.0">

        <!--removed html from url but still is html-->
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link href="http://amitmac.github.io/posts/2016-12-LOGREG/" rel="canonical" />
        <link rel="shortcut icon" href="../../images/favicon.ico">
        <link rel="stylesheet" type="text/css" href="../../jquery-ui-1.11.4/jquery-ui.css">
        <link rel="stylesheet" href="../../bootstrap/css/bootstrap.css">
        <link href="../../font-awesome/css/font-awesome.css" rel="stylesheet">
        <link href="../../css/sticky-footer-navbar.css" rel="stylesheet">
        <!--<link rel="stylesheet" href="../../css/default.css">-->
        <link rel="stylesheet" href="../../css/style.css">

        <link href="../../highlight/styles/github.css" rel="stylesheet">

        <link rel="stylesheet" href="../../highlight/styles/default.css">
        <script src="../../highlight/highlight.pack.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>

        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({tex2jax: {
                                    inlineMath: [['$','$'], ['\\(','\\)']]
                                },
                                CommonHTML: {
                                    scale: 100
                              }});
        </script>
        <script type="text/javascript" src="../../js/jquery-2.0.2.min.js"></script>
        <script type="text/javascript" src="../../jquery-ui-1.11.4/jquery-ui.js"></script>
        <script type="text/javascript" src="../../bootstrap/js/bootstrap.min.js"></script>
        <script type="text/javascript" src="../../js/script.js"></script>

        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

            ga('create', 'UA-65608932-1', 'auto');
            ga('send', 'pageview');
        </script>
    </head>
    <body class="blog">
        <div id="">
            <nav class="navbar navbar-inverse navbar-static-top" role="navigation">
                <div class="container">
                    <!--Toggle header for mobile-->
                    <div class="navbar-header">
                        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                            <span class="sr-only">Toggle navigation</span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </button>
                        <a class="navbar-brand active" href="../../index.html" id="home">ABOUT LEARNING</a>
                    </div>
                    <!--normal header-->
                    <div class="navbar-collapse collapse">
                        <ul class="nav navbar-nav navbar-right">
                            <li><a href="../../index.html"><span class="glyphicon glyphicon-pencil"></span>  Blog</a></li>
                            <li><a href="../../about.html"><span class="glyphicon glyphicon-user"></span>  About</a></li>
                            <li><a href="../../contact.html"><span class="glyphicon glyphicon-envelope"></span>  Contact</a></li>
                        </ul>
                    </div><!--/.nav-collapse -->
                </div>
            </nav>
            <div class="content">
                <div class="container">
                    <div class="row">
                        <div class="col-md-8 col-md-offset-2">
                            <h2>Logistic Regression</h2>
                            <hr>
                            <p>There are many cases when the output is discrete rather than continuous. And many problems that have binary outcomes. And it would be a great deal if we can assign probabilities over the binary labels rather giving straight answer from the set {0,1}. In this way, we could be more confident about the labels further away from the decision boundary more likely to be correct. In short we want to have the conditional distribution of the label Y given the input variables, P(Y|X).</p>
<p>
Now instead of generating 0 or 1, we output P(Y=1|X). But how to model this probability as a function of X. We cannot use direct linear function here which is unbounded whereas we need a function bounded by 0 and 1. Instead we use logistic function, $ log \frac{p}{1-p}$ . This function can be used as linear function of x.</p>
<p style="text-align:center;">$ log \frac{p(y|x)}{1 - p(y|x)} = \theta_0 + \theta x $</p>
<p>On solving for probability, we can get an equation,</p>
<p>$ P(y=1|X, \theta , \theta_0) = \sigma (\theta_0 + \theta X) $ where $ \sigma (\theta_0 + \theta X) = \frac{1}{1 + e^{-(\theta_0 + \theta X)}} $ , is called sigmoid function</p>
<p>The graph of $ \sigma $ with x is shown below. As you can see, the value of $ \sigma $ is bounded by 0 and 1, therefore can be interpreted as probability.</p>
<div class="row top-buffer">
    <div class="col-md-8 col-md-offset-4">
        <div class="post">
            <img class="aligncenter" src="images/log-reg.png" alt="logistic regression" />
        </div>
    </div>
</div>
<p>To train such models, we try to maximize the probability that we predict the correct label. Assuming the observations are independent of each other, the conditional likelihood function is given by</p>
<p style="text-align:center;">$ \prod _{i=1}^{n}P(Y=y_i|X_i) = \prod p^{y_i}(1-p)^{1-y_i}$ .</p>
<p>Taking log both side gives the log likelihood (product might be too low, so we take log),</p>
<p style="text-align:center;">$ l(\theta , \theta_0) = \sum_{i=1}^{n} y_i log p(x_i) + (1 - y_i) log (1 - p(x_i)) $</p>
<p style="text-align:center;">= $ \sum_{i=1}^{n} log (1 - p(x_i)) + \sum_{i=1}^{n} y_i log \frac{p(x_i)}{1 - p(x_i)} $</p>
<p style="text-align:center;">= $ \sum_{i=1}^{n} log (1-p(x_i)) + \sum_{i=1}^{n} y_i (\theta_0 + x_i \theta) $</p>
<p style="text-align:center;">= $ \sum_{i=1}^{n} - log (1 + e^{\theta_0 + x_i \theta}) + \sum_{i=1}^{n} y_i (\theta_0 + x_i \theta) $</p>
<p>To find the Maximum likelihood estimate we differentiate log-likelihood with respect to the parameters,</p>
<p style="text-align:center;">$ \frac{\partial l}{\partial \theta_j} = \sum_{i=1}^{n} -x_{ij} (y_i - P(y_i | x_i, \theta , \theta_0)) $</p>
<p>Now we cannot put above derivative equal to zero. It has to be solved using numerical optimization. There are different methods proposed for solving it e.g. Newton's Method, Conjugate Gradient, L-BFGS and Trust Region(liblinear). But before that lets talk about Multinomial Logistic Regression or Softmax Regression.</p>

<strong>Softmax Regression</strong>

In logistic regression $ y_i \epsilon \{0, 1\}$ while in softmax regression $ y_i \epsilon \{1, 2,...., K \}$. Given a test input x, we want our hypothesis to estimate P(y=k | x) for each k = 1,2,...,K. Therefore the output is a K-dimensional vector which sum to 1. Probability in softmax is given by
<p style="text-align:center;">$ P(y^{(i)} = k | x^{(i)} ; \theta) = \frac{exp(\theta^{(k)T} x^{(i)})}{\sum_{j=1}^{K}exp(\theta^{(j)T} x^{(i)})} $</p>
<p style="text-align:center;">$ h_{\theta}(x) = \begin{bmatrix} P(y = 1 | x)\\ P(y = 2 | x)\\ .\\ .\\ .\\ P(y = K | x)\\ \end{bmatrix} = \frac{1}{\sum_{i=1}^{K}exp(\theta^{(i)T} x)} \begin{bmatrix} exp(\theta^{(1)T} x)\\ exp(\theta^{(2)T} x)\\ .\\ .\\ .\\ exp(\theta^{(K)T} x)\\ \end{bmatrix} $</p>
<p>The likelihood is given by</p>
<p style="text-align:center;">$ l( \theta ) = - \left [ \sum_{i=1}^{m} \sum_{k=1}^{K} 1\{ y^{(i)} = k\} log \frac{exp(\theta^{(k)T}x^{(i)})}{\sum_{j=1}^{K} exp(\theta^{(j)T} x^{(i)})} \right ] $</p>
The gradient with respect to theta parameters,
<p style="text-align:center;">$ \frac{\partial l}{\partial \theta_k} = \sum_{i=1}^{n} -x_{ij} (1\{y_i = k \} - P(y_i = k | x_i, \theta , \theta_0)) $</p>
<p>Given the derivative, we can now use numerical optimization algorithm like L-BFGS, Gradient Descent to minimize negative log-likelihood. For example in gradient descent,</p>
<p style="text-align:center;">$ \theta_j = \theta_j - \alpha \triangledown_{\theta_j}l(\theta) $</p>
<p><strong>Regularization</strong></p>
<p>Large parameters often lead to overfitting. We penalize large parameters values by adding a regularization or weight decay term $ \frac{\lambda}{2} \sum_{i=1}^{K} \sum_{j=0}^{n} \theta_{ij}^2 $ to the log likelihood or cost function. The gradient then looks like</p>
<p style="text-align:center;">$ \frac{\partial l}{\partial \theta_k} = \sum_{i=1}^{n} -x_{ij} (1\{y_i = k \} - P(y_i = k | x_i, \theta , \theta_0)) + \lambda \theta_k$</p>
<p>Below is a very simple implementation of Logistic Regression using Gradient Descent.</p>

<pre><code class="MATLAB">
function [theta,cost] = logistic_regression_train(X,y,num_iter)
	
    %X = featureNorm(X);
    [m,n] = size(X);
    X = [ones(m,1), X];
    theta = ones(n+1,1);
    cost = zeros(1,500);
    for i=1:num_iter
        alpha = 1/sqrt(i); %try changing different values like 1/sqrt(i),2/i...
        h = sigmoid(X * theta);
        theta = theta - alpha * X' * (h - y);
        cost(i) = sum(abs(h - y)) / m;
    end

end
</code></pre>
However, we can use built-in libraries of scikit-learn in python.
<pre><code class="MATLAB">
from sklearn.linear_model import LogisticRegression

logreg = LogisticRegression(penalty='l2', dual=False, tol=0.0001, \
                            C=1.0, fit_intercept=True, intercept_scaling=1, \
                            class_weight=None, random_state=None, \
                            solver='liblinear',max_iter=100, \
                            multi_class='ovr', verbose=0)

</code></pre>
<p>
We can tune parameters once we know the fundamentals of Logistic Regression. Like we can set regularization type using penalty parameter. Optimization algorithm can be set using solver parameter. Here it is set liblinear which implements Trust Region Method.
</p>
<p>
References:
<ul>
<li> <a href="http://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch12.pdf" target="_blank">http://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch12.pdf</a></li>
<li> <a href="http://ufldl.stanford.edu/wiki/index.php/Softmax_Regression" target="_blank">http://ufldl.stanford.edu/wiki/index.php/Softmax_Regression</a></li>
<li> <a href="https://en.wikipedia.org/wiki/Logistic_regression" target="_blank">https://en.wikipedia.org/wiki/Logistic_regression</a></li>
</ul>
</p>
                        </div>  
                    </div>
                    <div class="row">
                        <div class="col-md-8 col-md-offset-2">
                            <div id="disqus_thread"></div>
                            <script>
                                /**
                                 *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
                                 *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
                                 */
                                
                                var disqus_config = function () {
                                    this.page.url = "http://amitmac.github.io/posts/2016-12-LOGREG/";  // Replace PAGE_URL with your page's canonical URL variable
                                    this.page.identifier = "/posts/2016-12-LOGREG/"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
                                };

                                (function() {  // DON'T EDIT BELOW THIS LINE
                                    var d = document, s = d.createElement('script');
                                    
                                    s.src = '//amitmac-1.disqus.com/embed.js';
                                    
                                    s.setAttribute('data-timestamp', +new Date());
                                    (d.head || d.body).appendChild(s);
                                })();
                            </script>
                            <noscript>
                                Please enable JavaScript to view the 
                                <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
                            </noscript>
                        </div>
                    </div>         
                </div>
            </div>
        </div>
    <script id="dsq-count-scr" src="//amitmac-1.disqus.com/count.js" async></script>
    </body>
</html>
